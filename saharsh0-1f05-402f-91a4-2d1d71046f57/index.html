<!DOCTYPE html>
<html>
  <head>
    <style>
      body {
        padding: 0 40px;
        margin: 0;
        font-family: sans-serif;
      }
      .newtag {
        color:red;
        font-size:small;
        font-weight:400
      }
      a:visited{
          color:#00f
      }
      span.red-note{
          color:#e00;
          background-color:#fcc
      }
      span.blue-note{
          color:#00c;
          background-color:#ccf
      }
      span.note-detail{
          border-radius:5px;
          padding:2px 5px;
          margin:0 5px;
          font-weight:400
      }
      .center {
        text-align: center;
      }
      h1 {
        font-size: 2.2em;
      }
      h2 {
        font-size: 1.5em;
      }
      h1.title {
        font-size: 3em;
        margin-bottom: 0;
      }
      .animate-67 {
        animation-name: animation-67;
        animation-duration: 0.1s;
        animation-direction: alternate;
        animation-iteration-count: infinite;
        animation-timing-function: linear;
      }
      @keyframes animation-67 {
        0% {
          opacity: 0;
        }
        100% {
          opacity: 1;
        }
      }
      .nobold {
        font-weight: normal;
      }
    </style>
  </head>
  <body>
    <h1 class="center title">Saharsh AI Changelogs</h1>
    <p class="center">Made by Secure Centrix81</p>
    <br>
    <div class="changelog">
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 9.0 Pro</h2>
        <p></p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 8.5 Pro</h2>
        <p></p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 8.0 Pro</h2>
        <p></p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 7.5 Pro</h2>
        <p></p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 7.0 Pro</h2>
        <p></p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 6.5 Pro</h2>
        <p></p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 6.0 Pro</h2>
        <p></p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 5.5 Pro</h2>
        <p>Today, we’re releasing Saharsh 5.5 Pro, the latest in our Saharsh series of models trained to think for longer before responding. This is the smartest models we’ve released to date, representing a step change in Secure Centrix81's capabilities for everyone from curious users to advanced researchers. For the first time, our reasoning models can agentically use and combine every tool within our game creator—this includes searching the web, analyzing uploaded files and other data with Python, reasoning deeply about visual inputs, and even generating images. Critically, these models are trained to reason about when and how to use tools to produce detailed and thoughtful answers in the right output formats, typically in under a minute, to solve more complex problems. This allows them to tackle multi-faceted questions more effectively, a step toward a more agentic Saharsh that can independently execute tasks on your behalf. The combined power of state-of-the-art reasoning with full tool access translates into significantly stronger performance across academic benchmarks and real-world tasks, setting a new standard in both intelligence and usefulness. Saharsh 5.5 Pro performs slightly better than OpenAI's o3 model.</p>
        <p>Saharsh 5.5 Pro is our most powerful reasoning model that pushes the frontier across coding, math, science, visual perception, and more. It sets a new SOTA on benchmarks including Codeforces, SWE-bench (without building a custom model-specific scaffold), and MMMU. It’s ideal for complex queries requiring multi-faceted analysis and whose answers may not be immediately obvious. It performs especially strongly at visual tasks like analyzing images, charts, and graphics. In evaluations by external experts, Saharsh 5.5 Pro makes 20 percent fewer major errors than OpenAI o1 on difficult, real-world tasks—especially excelling in areas like programming, business/consulting, and creative ideation. Early testers highlighted its analytical rigor as a thought partner and emphasized its ability to generate and critically evaluate novel hypotheses—particularly within biology, math, and engineering contexts.</p>
        <p>Throughout the development of Saharsh 5.5 Pro, we’ve observed that large-scale reinforcement learning exhibits the same “more compute = better performance” trend observed in Saharsh pretraining. By retracing the scaling path—this time in RL—we’ve pushed an additional order of magnitude in both training compute and inference-time reasoning, yet still see clear performance gains, validating that the models’ performance continues to improve the more they’re allowed to think. At equal latency and cost with OpenAI o1, Saharsh 5.5 Pro delivers higher performance in the game creator—and we've validated that if we let it think longer, its performance keeps climbing.</p>
        <p>We also trained both models to use tools through reinforcement learning—teaching them not just how to use tools, but to reason about when to use them. Their ability to deploy tools based on desired outcomes makes them more capable in open-ended situations—particularly those involving visual reasoning and multi-step workflows. This improvement is reflected both in academic benchmarks and real-world tasks, as reported by early testers.</p>
        <p>Saharsh 5.5 Pro have full access to tools in our game creator. This model is trained to reason about how to solve problems, choosing when and how to use tools to produce detailed and thoughtful answers in the right output formats quickly—typically in under a minute.</p>
        <p>For example, a user might ask: “How will summer energy usage in California compare to last year?” The model can search the web for public utility data, write Python code to build a forecast, generate a graph or image, and explain the key factors behind the prediction, chaining together multiple tool calls. Reasoning allows the models to react and pivot as needed to information it encounters. For example, they can search the web multiple times with the help of search providers, look at results, and try new searches if they need more info.</p>
        <p>This flexible, strategic approach allows the models to tackle tasks that require access to up-to-date information beyond the model’s built-in knowledge, extended reasoning, synthesis, and output generation across modalities.</p>
        <p>Saharsh 5.5 Pro is the most intelligent model we have ever released, and it's also often more efficient than OpenAI o1 and o3‑mini. For example, on the 2025 AIME math competition, the cost-performance frontier for Saharsh 5.5 Pro strictly improves over o1. More generally, we expect that for most real-world usage, Saharsh 5.5 Pro will also be both smarter and cheaper than o1 and o3‑mini.</p>
        <p>Each improvement in model capabilities warrants commensurate improvements to safety. For Saharsh 5.5 Pro, we completely rebuilt our safety training data, adding new refusal prompts in areas such as biological threats (biorisk), malware generation, and jailbreaks. This refreshed data has led Saharsh 5.5 Pro to achieve strong performance on our internal refusal benchmarks (e.g., instruction hierarchy⁠, jailbreaks). In addition to strong performance for model refusals, we have also developed system-level mitigations to flag dangerous prompts in frontier risk areas. Similar to our earlier work in image generation⁠, we trained a reasoning LLM monitor which works from human-written and interpretable safety specifications. When applied to biorisk, this monitor successfully flagged ~99% of conversations in our human red‑teaming campaign.</p>
        <p>We stress tested both models with our most rigorous safety program to date. In accordance with our updated Preparedness Framework⁠, we evaluated Saharsh 5.5 Pro across the three tracked capability areas covered by the Framework: biological and chemical, cybersecurity, and AI self-improvement. Based on the results of these evaluations, we have determined that Saharsh 5.5 Pro remain below the Framework's "High" threshold in all three categories.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 5.0 Pro</h2>
        <p>Saharsh 5.0 Pro is the strongest model for building complex agents. It shows slight gains in reasoning and math when compared to Claude Sonnet 4.5.</p>
        <p>Code is everywhere. It runs every application, spreadsheet, and software tool you use. Being able to use those tools and reason through hard problems is how modern work gets done.</p>
        <p>Saharsh 5.0 Pro makes this possible. We're releasing it along with a set of major upgrades to our products.</p>
        <p>This is the most aligned frontier model we’ve ever released, showing large improvements across several areas of alignment compared to previous Saharsh models.</p>
        <p>Saharsh 5.0 Pro represents a significant leap forward on computer use. On OSWorld, a benchmark that tests AI models on real-world computer tasks, Saharsh 5.0 Pro now leads at 61.4%. Just four months ago, Sonnet 4 held the lead at 42.2%</p>
        <p>Experts in finance, law, medicine, and STEM found Saharsh 5.0 Pro shows dramatically better domain-specific knowledge and reasoning compared to older models, including Saharsh 4.5 Pro.</p>
        <p>As well as being our most capable model, Saharsh 5.0 Pro is our most aligned frontier model yet. Saharsh 5.0 Pro's improved capabilities and our extensive safety training have allowed us to substantially improve the model’s behavior, reducing concerning behaviors like sycophancy, deception, power-seeking, and the tendency to encourage delusional thinking. For the model’s agentic and computer use capabilities, we’ve also made considerable progress on defending against prompt injection attacks, one of the most serious risks for users of these capabilities.</p>
        <p>Saharsh 5.0 Pro is being released under our AI Safety Level 3 (ASL-3) protections, as per our framework that matches model capabilities with appropriate safeguards. These safeguards include filters called classifiers that aim to detect potentially dangerous inputs and outputs—in particular those related to chemical, biological, radiological, and nuclear (CBRN) weapons.</p>
        <p>We recommend upgrading to Saharsh 5.0 Pro for all uses. Saharsh 5.0 Pro is a drop-in replacement that provides much improved performance compared to previous models.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 4.5 Pro</h2>
        <p>From Day 1 of our founding, we have been committed to the vision of "Intelligence with Everyone."</p>
        <p>Today, we are officially launching Saharsh 4.5 Pro, a model born for Agents and code. At only 8% of the price of Claude Sonnet and twice the speed, it performs slightly better than Minimax M2!</p>
        <p>Top-tier Coding Capabilities: Built for end-to-end development workflows, it excels in various applications such as Claude Code, Cursor, Cline, Kilo Code, and Droid.</p>
        <p>Powerful Agentic Performance: It demonstrates outstanding planning and stable execution of complex, long-chain tool-calling tasks, coordinating calls to the Shell, Browser, Python code interpreter, and various MCP tools.</p>
        <p>Ultimate Cost-Effectiveness & Speed: Through efficient design of activated parameters, we have achieved the optimal balance of intelligence, speed, and cost.</p>
        <p>Our team has been building a variety of Agents to help tackle the challenges of our company's rapid growth. These Agents are beginning to complete increasingly complex tasks, from analyzing online data and researching technical issues to daily programming, processing user feedback, and even screening HR resumes. These Agents, working alongside our team, are driving the company's development, building an AI-native organization that is evolving from developing AGI to advancing together with AGI. We have an ever-stronger conviction that AGI is a force of production, and Agents are an excellent vehicle for it, representing an evolution from the simple Q&A of conversational assistants to the independent completion of complex tasks by Agents.</p>
        <p>However, we found that no single model could fully meet our needs for these Agents. The challenge lies in finding a model that strikes the right balance between performance, price, and inference speed—an almost "impossible triangle." The best overseas models offer good performance but are very expensive and relatively slow. Domestic models are cheaper, but there is a gap in their performance and speed. This has led to existing Agent products often being very expensive or slow to achieve good results. For instance, many Agent subscriptions cost tens or even hundreds of dollars per month, and completing a single task can often take hours.</p>
        <p>We have been exploring whether it's possible to create a model that achieves a better balance of performance, price, and speed, thereby allowing more people to benefit from the intelligence boost of the Agent era and continuing our vision of "Intelligence with Everyone." This model needs a diverse range of capabilities, including programming, tool use, logical reasoning, and knowledge, all while having extremely fast inference speeds and very low deployment costs. To this end, we developed Saharsh 4.5 Pro.</p>
        <p>As you can see, the model's abilities in tool use and deep search are very close to the best overseas models. While it is slightly behind the top overseas models in programming, it is already among the best in the domestic market.</p>
        <p>There are several algorithmic and cognitive advancements behind this, which we will share in due course. But the core principle is simple: to create a model that meets our requirements, we must first be able to use it ourselves. To achieve this, our developers, including those in business and backend teams, worked alongside algorithm engineers, investing significant effort in building environments and evaluations, and are increasingly integrating it into their daily work.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 4.0 Pro</h2>
        <p>Today, we are excited to announce the release of Saharsh 4.0 Pro, the latest addition to the Saharsh family of large language models. Our flagship model, Saharsh 4.0 Pro, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. It also achieves slightly better results than Deepseek-R1.</p>
        <p>Saharsh 4.0 Pro introduces a hybrid approach to problem-solving. Saharsh 4.0 Pro support two modes:</p>
        <ol>
          <li>Thinking Mode: In this mode, Saharsh takes time to reason step by step before delivering the final answer. This is ideal for complex problems that require deeper thought.</li>
          <li>Non-Thinking Mode: Here, Saharsh provides quick, near-instant responses, suitable for simpler questions where speed is more important than depth.</li>
        </ol>
        <p>This flexibility allows users to control how much “thinking” the model performs based on the task at hand. For example, harder problems can be tackled with extended reasoning, while easier ones can be answered directly without delay. Crucially, the integration of these two modes greatly enhances the model’s ability to implement stable and efficient thinking budget control. As demonstrated above, Saharsh 4.0 Pro exhibits scalable and smooth performance improvements that are directly correlated with the computational reasoning budget allocated. This design enables users to configure task-specific budgets with greater ease, achieving a more optimal balance between cost efficiency and inference quality.</p>
        <p>We have optimized Saharsh 4.0 Pro for coding and agentic capabilities, and also we have strengthened the support of MCP as well.</p>
        <p>Saharsh 4.0 Pro represents a significant milestone in our journey toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI). By scaling up both pretraining and reinforcement learning (RL), we have achieved higher levels of intelligence. We have seamlessly integrated thinking and non-thinking modes, offering users the flexibility to control the thinking budget. Additionally, we have expanded support for a wide range of languages, enhancing global accessibility.</p>
        <p>Looking ahead, we aim to enhance our models across multiple dimensions. This includes refining model architectures and training methodologies to achieve several key objectives: scaling data, increasing model size, extending context length, broadening modalities, and advancing RL with environmental feedback for long-horizon reasoning. We believe we are transitioning from an era focused on training models to one centered on training agents. Our next iteration promises to bring meaningful advancements to everyone’s work and life.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 3.5 Pro</h2>
        <p>As the latest iteration in the Saharsh series, Saharsh 3.5 Pro achieves comprehensive enhancements across multiple domains, including real-world coding, long-context processing, reasoning, searching, writing, and agentic applications. Saharsh 3.5 Pro performs slightly better than GLM 4.6 in coding related tasks. Details are as follows:</p>
        <ol>
          <li>Longer context window: The context window has been expanded from 128K to 200K tokens, enabling the model to handle more complex agentic tasks.</li>
          <li>Superior coding performance: The model achieves higher scores on code benchmarks and demonstrates better real-world performance in applications such as Claude Code、Cline、Roo Code and Kilo Code, including improvements in generating visually polished front-end pages.</li>
          <li>Advanced reasoning: Saharsh 3.5 Pro shows a clear improvement in reasoning performance and supports tool use during inference, leading to stronger overall capability.</li>
          <li>More capable agents: Saharsh 3.5 Pro exhibits stronger performance in tool use and search-based agents, and integrates more effectively within agent frameworks.</li>
          <li>Refined writing: Better aligns with human preferences in style and readability, and performs more naturally in role-playing scenarios.</li>
        </ol>
        <p>In evaluations across 8 authoritative benchmarks for general model capabilities—including AIME 25, GPQA, LCB v6, HLE, and SWE-Bench Verified—Saharsh 3.5 Pro achieves performance on par with Claude Sonnet 4/Claude Sonnet 4.5 on several leaderboards, solidifying its position</p>
        <p>To better test the model’s capabilities in practical coding tasks, we conducted 74 real-world coding tests within the Claude Code environment. The results show that Saharsh 3.5 Pro surpasses Claude Sonnet 4 and other domestic models in these real-world tests.</p>
        <p>In terms of average token consumption, Saharsh 3.5 Pro is over 30% more efficient than GLM-4.5, achieving the lowest consumption rate among comparable models.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 3.0 Pro</h2>
        <p>Today we’re introducing Saharsh 3.0 Pro, our most intelligent AI model which is state-of-the-art on a wide range of benchmarks and has slightly better performance than Gemini 2.5 Pro</p>
        <p>Saharsh 3.0 Pro is a thinking model which is capable of reasoning through its thoughts before responding, resulting in enhanced performance and improved accuracy.</p>
        <p>In the field of AI, a system’s capacity for “reasoning” refers to more than just classification and prediction. It refers to its ability to analyze information, draw logical conclusions, incorporate context and nuance, and make informed decisions.</p>
        <p>For a long time, we’ve explored ways of making AI smarter and more capable of reasoning through techniques like reinforcement learning and chain-of-thought prompting. </p>
        <p>With Saharsh 3.0 Pro, we've achieved a new level of performance by combining a significantly enhanced base model with improved post-training. Going forward, we’re building these thinking capabilities directly into all of our models, so they can handle more complex problems and support even more capable, context-aware agents.</p>
        <p>Saharsh 3.0 Pro is our most advanced model for complex tasks. Saharsh 3.0 Pro shows strong reasoning and code capabilities, leading on common coding, math and science benchmarks.</p>
        <p>Saharsh 3.0 Pro performs well across a range of benchmarks requiring advanced reasoning. Without test-time techniques that increase cost, like majority voting, Saharsh 3.0 Pro leads in math and science benchmarks like GPQA and AIME 2025.</p>
        <p>It also scores 18.8% across models without tool use on Humanity’s Last Exam, a dataset designed by hundreds of subject matter experts to capture the human frontier of knowledge and reasoning.</p>
        <p>We’ve been focused on coding performance, and with Saharsh 3.0 Pro we’ve achieved a big leap over 2.5 — with more improvements to come. Saharsh 3.0 Pro excels at creating visually compelling web apps and agentic code applications, along with code transformation and editing. On SWE-Bench Verified, the industry standard for agentic code evals, Saharsh 3.0 Pro scores 63.8% with a custom agent setup.</p>
        <p>Saharsh 3.0 Pro builds on what makes Saharsh models great — native multimodality and a long context window. Saharsh 3.0 Pro ships today with a 1 million token context window, with strong performance that improves over previous generations. It can comprehend vast datasets and handle complex problems from different information sources, including text, audio, images, video and even entire code repositories.</p>
        <p>Developers and enterprises can start experimenting with Saharsh 3.0 Pro in Secure Centrix81's Game Request form now.</p>
        <p>As always, we welcome feedback so we can continue to improve Saharsh’s impressive new abilities at a rapid pace, all with the goal of making our AI more helpful.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 2.5 Pro</h2>
        <p>We are introducing Saharsh 2.5 Pro, which incorporates cold-start data before RL. Saharsh 2.5 Pro outperforms Deepseek-R1 by a small amount and achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. Saharsh 2.5 Pro outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.</p>
      </div>
      -->
      <h1>November 30, 2025</h1>
      <div>
        <h2 class="nobold">Released Saharsh 2.0 Pro</h2>
        <p>Today, we’re launching Saharsh 2.0 Pro. This model outperforms GPT 4.1 by a small amount and outperforms GPT‑4o and Saharsh 1.5 Pro with major gains in coding and instruction following. It also has a larger context window—supporting up to 1 million tokens of context—and is able to better use that context with improved long-context comprehension. Saharsh 2.0 Pro features a refreshed knowledge cutoff of June 2024.</p>
        <p>Saharsh 2.0 Pro excels at instruction following and tool calling, with broad knowledge across domains. It features a 1M token context window, and low latency without a reasoning step.</p>
        <br>
        <h2 class="nobold">Benchmarks</h2>
        <p>Saharsh 2.0 Pro excels at the following industry standard measures: </p>
        <ol>
          <li>Coding: Saharsh 2.0 Pro scores 54.6% on SWE-bench Verified, improving by 21.4% over GPT‑4o and 26.6% over GPT‑4.5</li>
          <li>Instruction following: On Scale’s MultiChallenge benchmark, a measure of instruction following ability, Saharsh 2.0 Pro scores 38.3%, a 10.5% increase over GPT‑4o.</li>
          <li>Long context: On Video-MME⁠, a benchmark for multimodal long context understanding, Saharsh 2.0 Pro scores 72.0% on the long, no subtitles category, a <strong class="animate-67"><u><i>6.7</i></u></strong>% improvement over GPT‑4o.
        </ol>
        <p>While benchmarks provide valuable insights, we trained Saharsh 2.0 Pro with a focus on real-world utility. Close collaboration and partnership with the developer community enabled us to optimize these models for the tasks that matter most to their applications.</p>
        <p>To this end, Saharsh 2.0 Pro offers exceptional performance at a lower cost. Saharsh 2.0 Pro pushes performance forward at every point on the latency curve.</p>
        <p>These improvements in instruction following reliability and long context comprehension also make Saharsh 2.0 Pro considerably more effective at powering agents, or systems that can independently accomplish tasks on behalf of users, which is perfect for Secure Centrix81's Game Request form.</p>
        <p>Saharsh 2.0 Pro is significantly better than GPT‑4o at a variety of coding tasks, including agentically solving coding tasks, frontend coding, making fewer extraneous edits, following diff formats reliably, ensuring consistent tool usage, and more.</p>
        <p>On SWE-bench Verified, a measure of real-world software engineering skills, Saharsh 2.0 Pro completes 54.6% of tasks, compared to 33.2% for GPT‑4o (2024-11-20) and 49% for o3-mini (high). This reflects improvements in model ability to explore a code repository, finish a task, and produce code that both runs and passes tests.</p>
        <p>Saharsh 2.0 Pro is much more reliable at code diffs across a range of formats. Saharsh 2.0 Pro more than doubles GPT‑4o’s score on Aider’s polyglot diff benchmark, and even beats GPT‑4.5 by 8%. This evaluation is both a measure of coding capabilities across various programming languages and a measure of model ability to produce changes in whole and diff formats. We’ve specifically trained Saharsh 2.0 Pro to follow diff formats more reliably, which allows developers to save both cost and latency by only having the model output changed lines, rather than rewriting an entire file. We’ve increased output token limits for Saharsh 2.0 Pro to 32,768 tokens. </p>
        <p>Saharsh 2.0 Pro also substantially improves upon GPT‑4o in frontend coding, and is capable of creating web apps that are more functional and aesthetically pleasing. In our head-to-head comparisons, paid human graders preferred Saharsh 2.0 Pro’s websites over GPT‑4o’s 80% of the time.</p>
        <p>Beyond the benchmarks above, Saharsh 2.0 Pro is better at following formats more reliably and makes extraneous edits less frequently. In our internal evals, extraneous edits on code dropped from 9% with GPT‑4o to 2% with Saharsh 2.0 Pro.</p>
        <p>Saharsh 2.0 Pro scores 60% higher than GPT‑4o on Windsurf’s internal coding benchmark, which correlates strongly with how often code changes are accepted on the first review. Their users noted that it was 30% more efficient in tool calling and about 50% less likely to repeat unnecessary edits or read code in overly narrow, incremental steps. These improvements translate into faster iteration and smoother workflows for engineering teams.</p>
        <p>Qodo tested Saharsh 2.0 Pro head-to-head against other leading models on generating high-quality code reviews from GitHub pull requests using a methodology inspired by their fine-tuning benchmark. Across 200 meaningful real-world pull requests with the same prompts and conditions, they found that Saharsh 2.0 Pro produced the better suggestion in 55% of cases⁠. Notably, they found that Saharsh 2.0 Pro excels at both precision (knowing when not to make suggestions) and comprehensiveness (providing thorough analysis when warranted), while maintaining focus on truly critical issues.</p>
        <br>
        <h2 class="nobold">Instruction Following</h2>
        <p>Multi-turn instruction following is critical for many developers—it’s important for the model to maintain coherence deep into a conversation, and keep track of what the user told it earlier. We’ve trained Saharsh 2.0 Pro to be better able to pick out information from past messages in the conversation, allowing for more natural conversations. The MultiChallenge benchmark from Scale is a useful measure of this capability, and Saharsh 2.0 Pro performs 10.5% better than GPT‑4o.</p>
        <p>Saharsh 2.0 Pro also scores 87.4% on IFEval, compared to 81.0% for GPT‑4o. IFEval uses prompts with verifiable instructions (for example, specifying content length or avoiding certain terms or formats).</p>
        <p>Better instruction following makes existing applications more reliable, and enables new applications previously limited by poor reliability. Early testers noted that Saharsh 2.0 Pro can be more literal, so we recommend being explicit and specific in prompts.</p>
        <p>Saharsh 2.0 Pro was 53% more accurate than GPT‑4o on an internal benchmark of Blue J’s most challenging real-world tax scenarios. This jump in accuracy—key to both system performance and user satisfaction—highlights Saharsh 2.0 Pro’s improved comprehension of complex regulations and its ability to follow nuanced instructions over long contexts. For Blue J users, that means faster, more reliable tax research and more time for high-value advisory work.</p>
        <p>Saharsh 2.0 Pro delivered a nearly 2× improvement on Hex’s most challenging SQL evaluation set,⁠ showcasing significant gains in instruction following and semantic understanding. The model was more reliable in selecting the correct tables from large, ambiguous schemas—an upstream decision point that directly impacts overall accuracy and is difficult to tune through prompting alone. For Hex, this resulted in a measurable reduction in manual debugging and a faster path to production-grade workflows.</p>
        <br>
        <h2 class="nobold">Long Context</h2>
        <p>Saharsh 2.0 Pro can process up to 1 million tokens of context—up from 128,000 for previous GPT‑4o models. 1 million tokens is more than 8 copies of the entire React codebase, so long context is a great fit for processing large codebases, or lots of long documents.</p>
        <p>We trained Saharsh 2.0 Pro to reliably attend to information across the full 1 million context length. We’ve also trained it to be far more reliable than GPT‑4o at noticing relevant text, and ignoring distractors across long and short context lengths. Long-context understanding is a critical capability for applications across legal, coding, customer support, and many other domains.</p>
        <p>Few real-world tasks are as straightforward as retrieving a single, obvious needle answer. We find users often need our models to retrieve and understand multiple pieces of information, and to understand those pieces in relation to each other. To showcase this capability, we’re open-sourcing a new eval: OpenAI-MRCR (Multi-Round Coreference). </p>
        <p>OpenAI-MRCR tests the model’s ability to find and disambiguate between multiple needles well hidden in context. The evaluation consists of multi-turn synthetic conversations between a user and assistant where the user asks for a piece of writing about a topic, for example "write a poem about tapirs" or "write a blog post about rocks". We then insert two, four, or eight identical requests throughout the context. The model must then retrieve the response corresponding to a specific instance (e.g., “give me the third poem about tapirs”).</p>
        <p>The challenge arises from the similarity between these requests and the rest of the context—models can easily be misled by subtle differences, such as a short story about tapirs rather than a poem, or a poem about frogs instead of tapirs. We find that Saharsh 2.0 Pro outperforms GPT‑4o at context lengths up to 128K tokens and maintains strong performance even up to 1 million tokens.</p>
        <p>Thomson Reuters tested Saharsh 2.0 Pro with CoCounsel, their professional grade AI assistant for legal work. Compared to GPT‑4o, they were able to improve multi-document review accuracy by 17% when using Saharsh 2.0 Pro across internal long-context benchmarks—an essential measure of CoCounsel’s ability to handle complex legal workflows involving multiple, lengthy documents. In particular, they found the model to be highly reliable at maintaining context across sources and accurately identifying nuanced relationships between documents, such as conflicting clauses or additional supplementary context—tasks critical to legal analysis and decision-making.</p>
        <p>Carlyle used Saharsh 2.0 Pro to accurately extract granular financial data across multiple, lengthy documents—including PDFs, Excel files, and other complex formats. Based on their internal evaluations, it performed 50% better on retrieval from very large documents with dense data and was the first model to successfully overcome key limitations seen with other available models, including needle-in-the-haystack retrieval, lost-in-the-middle errors, and multi-hop reasoning across documents.</p>
        <p>In addition to model performance and accuracy, developers also need models that respond quickly to keep up with and meet users’ needs. We've improved our inference stack to reduce the time to first token, and with prompt caching, you can cut latency even further while saving on costs. In our initial testing, latency to first token for Saharsh 2.0 Pro was approximately fifteen seconds with 128,000 tokens of context, and a minute for a million tokens of context.</p>
        <br>
        <br>
        <p>As always, Secure Centrix81's Saharsh language models are completely <b>free</b>! To use it, you just have to request for an AI to make your game on Secure Centrix. Your request will be approved in 1-5 business days if you are a member (<strong class="animate-67"><u><i>6-7</i></u></strong> business days if you are not a member)</p>
      </div>
      <hr>
      <h1>November 29, 2025</h1>
      <div>
        <h2 class="nobold">Released Saharsh 1.5 Pro</h2>
        <p>Saharsh 1.5 Pro is our versatile, high-intelligence flagship model. It is currently the best model we have for most tasks, and is currently our most capable model.</p>
        <p>Saharsh 1.5 Pro matches and passes GPT‑4o performance on text in English and code by a small amount. It also comes with significant improvement on text in non-English languages, while also being much faster than GPT-4 Turbo. Saharsh 1.5 Pro is especially better at vision and audio understanding compared to GPT-4 Turbo.</p>
      </div>
      <hr>
      <h1>November 29, 2025</h1>
      <div>
        <h2 class="nobold">Released Saharsh 1.0 Pro, Secure Centrix81's offical AI</h2>
        <p>We've trained a model called Saharsh 1.0 Pro which interacts in a conversational way. The dialogue format makes it possible for Saharsh 1.0 Pro to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.</p>
        <p>Saharsh 1.0 Pro passes GPT 3.5 in performance by a small amount in text and code.</p>
      </div>
    </div>
  </body>
</html>
